{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d86c0d",
   "metadata": {},
   "source": [
    "# Multi-Class CNN untuk Deteksi Serangan Siber\n",
    "\n",
    "Notebook ini mendemonstrasikan cara melatih Convolutional Neural Network (CNN) untuk mengklasifikasikan berbagai jenis serangan siber.\n",
    "Kita akan melalui langkah-langkah berikut:\n",
    "1. **Memuat dan Eksplorasi Data**: Membaca dataset dan memahami strukturnya.\n",
    "2. **Visualisasi Data Awal**: Melihat distribusi kelas sebelum diproses.\n",
    "3. **Preprocessing Data**: Mengubah label menjadi angka, penskalaan fitur numerik, dan menangani variabel kategorikal.\n",
    "4. **Menangani Data Tidak Seimbang (Imbalanced Data)**: Menggunakan SMOTE dan RandomOverSampler untuk menyeimbangkan dataset.\n",
    "5. **Persiapan Data untuk CNN**: Mengubah bentuk data (reshape) ke format 3D yang dibutuhkan oleh CNN.\n",
    "6. **Membangun Model CNN**: Membuat arsitektur CNN 1D.\n",
    "7. **Melatih Model**: Melatih model dengan callbacks untuk performa optimal.\n",
    "8. **Evaluasi dan Visualisasi**: Memeriksa akurasi, confusion matrix, dan kurva pembelajaran.\n",
    "9. **Menyimpan Model**: Menyimpan model yang telah dilatih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style untuk plot\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15455d8",
   "metadata": {},
   "source": [
    "## 1. Memuat Data\n",
    "Kita memuat dataset dari file CSV `cyberfeddefender_dataset.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36708d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cyberfeddefender_dataset.csv')\n",
    "print(\"Ukuran Dataset:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fe6a2",
   "metadata": {},
   "source": [
    "## 2. Mapping Label & Visualisasi Awal\n",
    "Kita mengubah label string ('Normal', 'DDoS', 'Ransomware', 'Brute Force') menjadi nilai numerik (0, 1, 2, 3) agar dapat diproses oleh model.\n",
    "Selain itu, kita akan memvisualisasikan distribusi kelas untuk melihat apakah data seimbang atau tidak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609756b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'Normal': 0, 'DDoS': 1, 'Ransomware': 2, 'Brute Force': 3}\n",
    "df['True_Label'] = df['Attack_Type'].map(label_mapping)\n",
    "class_names = ['Normal', 'DDoS', 'Ransomware', 'Brute Force']\n",
    "\n",
    "print(\"Distribusi kelas sebelum oversampling:\")\n",
    "print(df['True_Label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffeba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Distribusi Kelas Awal\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x='True_Label', data=df, palette='viridis')\n",
    "ax.set_xticklabels(class_names)\n",
    "plt.title('Distribusi Kelas Sebelum Oversampling', fontsize=14)\n",
    "plt.xlabel('Tipe Serangan')\n",
    "plt.ylabel('Jumlah Sampel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab323d7",
   "metadata": {},
   "source": [
    "## 3. Preprocessing & Oversampling\n",
    "Kita memisahkan fitur (X) dan target (y). Kita juga mendefinisikan kolom mana yang numerik dan mana yang kategorikal.\n",
    "Kita menggunakan `ColumnTransformer` untuk menerapkan:\n",
    "- `StandardScaler` pada fitur numerik (untuk normalisasi).\n",
    "- `OneHotEncoder` pada fitur kategorikal (untuk mengubahnya menjadi format numerik).\n",
    "\n",
    "Kemudian kita menggunakan `SMOTE` dan `RandomOverSampler` untuk menyeimbangkan kelas, memastikan model tidak bias terhadap kelas mayoritas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c48e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan fitur dan target\n",
    "X = df.drop(columns=['Label', 'Attack_Type', 'Timestamp', 'Source_IP', 'Destination_IP'])\n",
    "y = df['True_Label']\n",
    "\n",
    "# Definisi fitur\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = ['Protocol', 'Flags']\n",
    "\n",
    "# Membuat preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Definisi pipeline oversampling\n",
    "smote = SMOTE(sampling_strategy='not majority', k_neighbors=5, random_state=42)\n",
    "ros = RandomOverSampler(sampling_strategy='all', random_state=42)\n",
    "\n",
    "balancing_pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', smote),\n",
    "    ('ros', ros)\n",
    "])\n",
    "\n",
    "print(\"Sedang melakukan oversampling...\")\n",
    "X_balanced, y_balanced = balancing_pipeline.fit_resample(X, y)\n",
    "\n",
    "print(\"\\nDistribusi kelas SETELAH oversampling:\")\n",
    "for i in range(4):\n",
    "    count = np.sum(y_balanced == i)\n",
    "    print(f\"  {i} - {class_names[i]:12} -> {count} sampel\")\n",
    "print(f\"Total sampel: {len(X_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75206bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Distribusi Kelas Setelah Oversampling\n",
    "plt.figure(figsize=(8, 5))\n",
    "unique, counts = np.unique(y_balanced, return_counts=True)\n",
    "ax = sns.barplot(x=unique, y=counts, palette='viridis')\n",
    "ax.set_xticklabels(class_names)\n",
    "plt.title('Distribusi Kelas Setelah Oversampling', fontsize=14)\n",
    "plt.xlabel('Tipe Serangan')\n",
    "plt.ylabel('Jumlah Sampel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae0bc1",
   "metadata": {},
   "source": [
    "## 4. Split Data dan Reshape\n",
    "Kita membagi data menjadi set pelatihan dan pengujian (70% latih, 30% uji).\n",
    "CNN mengharapkan input dalam format 3D: `(samples, time_steps, features)`. Karena kita memiliki data tabular 1D, kita mengubah bentuknya menjadi `(samples, features, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc64f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode target\n",
    "y_cat = to_categorical(y_balanced, num_classes=4)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_cat, test_size=0.3, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# Reshape untuk CNN 1D\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "print(f\"Ukuran Train: {X_train.shape}\")\n",
    "print(f\"Ukuran Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996c60c",
   "metadata": {},
   "source": [
    "## 5. Membangun Model CNN\n",
    "Kita membangun Convolutional Neural Network 1D.\n",
    "- **Conv1D**: Mengekstrak fitur dari input.\n",
    "- **BatchNormalization**: Menstabilkan pembelajaran.\n",
    "- **MaxPooling1D**: Mengurangi dimensi data.\n",
    "- **Dropout**: Mencegah overfitting.\n",
    "- **Dense**: Layer fully connected untuk klasifikasi akhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(64, 3, activation='relu', padding='same'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv1D(256, 3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa042650",
   "metadata": {},
   "source": [
    "## 6. Melatih Model\n",
    "Kita melatih model menggunakan:\n",
    "- **EarlyStopping**: Menghentikan pelatihan jika akurasi validasi tidak meningkat selama 3 epoch.\n",
    "- **ReduceLROnPlateau**: Mengurangi learning rate jika loss validasi stagnan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed9503",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy', patience=3, restore_best_weights=True, mode='max', verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=8, min_lr=1e-7, verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddba0f6",
   "metadata": {},
   "source": [
    "## 7. Evaluasi & Visualisasi\n",
    "Kita mengevaluasi model pada data uji dan menampilkan laporan klasifikasi serta visualisasi performa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"AKURASI FINAL: {acc:.5f} -> {acc*100:.3f}%\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5631d",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Visualisasi confusion matrix untuk melihat seberapa baik model memprediksi setiap kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(9,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Confusion Matrix - Akurasi: {acc*100:.3f}%', fontsize=16)\n",
    "plt.ylabel('Label Asli', fontsize=14)\n",
    "plt.xlabel('Label Prediksi', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc91ae0",
   "metadata": {},
   "source": [
    "### Kurva Pembelajaran (Learning Curves)\n",
    "Plot akurasi dan loss selama epoch untuk memeriksa overfitting atau underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315890f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Akurasi Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')\n",
    "plt.title('Akurasi Model')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Akurasi')\n",
    "plt.legend(); plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Loss Train')\n",
    "plt.plot(history.history['val_loss'], label='Loss Validasi')\n",
    "plt.title('Loss Model')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429b77a",
   "metadata": {},
   "source": [
    "## 8. Menyimpan Model\n",
    "Kita menyimpan model yang telah dilatih ke file (`cnn_multiclass_model.h5`).\n",
    "Jika Anda menggunakan Google Colab, Anda dapat mengunduhnya menggunakan kode di bawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan model\n",
    "model_filename = 'cnn_multiclass_model.h5'\n",
    "model.save(model_filename)\n",
    "print(f\"Model disimpan sebagai {model_filename}\")\n",
    "\n",
    "# Kode untuk mengunduh jika berjalan di Colab (dikomentari)\n",
    "# try:\n",
    "#     from google.colab import files\n",
    "#     files.download(model_filename)\n",
    "# except ImportError:\n",
    "#     print(\"Tidak berjalan di Colab, model disimpan secara lokal.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
